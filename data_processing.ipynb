{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbfa9a89",
   "metadata": {},
   "source": [
    "Task 1 – Data Preprocessing for Machine Learning\n",
    "Objective\n",
    "\n",
    "The goal of preprocessing is to clean and prepare the dataset so that machine learning models can understand and learn from it effectively. Raw data often contains unnecessary columns, inconsistent formats, or values that require scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58911559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988f9d72",
   "metadata": {},
   "source": [
    "Loaded Dataset\n",
    "\n",
    "Dataset: House Price India.csv\n",
    "\n",
    "Shape: 14,620 rows × 23 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d41f543e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14620, 23)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"House Price India.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5e6518",
   "metadata": {},
   "source": [
    "Removed Unnecessary Columns\n",
    "\n",
    "Dropped id (just a unique identifier) and Date (not helpful in predicting price).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "53ca3a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14620, 21)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "df_processed = df.drop(columns=[\"id\", \"Date\"])\n",
    "df_processed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c601e619",
   "metadata": {},
   "source": [
    "Categorical Encoding\n",
    "\n",
    "Converted Postal Code into categorical values.\n",
    "\n",
    "Applied One-Hot Encoding, which created new columns for each postal code region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "563accef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat Postal Code as categorical and one-hot encode\n",
    "df_processed[\"Postal Code\"] = df_processed[\"Postal Code\"].astype(\"category\")\n",
    "df_processed = pd.get_dummies(df_processed, columns=[\"Postal Code\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07327f81",
   "metadata": {},
   "source": [
    "Scaling Features\n",
    "\n",
    "Used StandardScaler to normalize all numerical features so that values are on a similar scale.\n",
    "\n",
    "This prevents large-value columns (like lot area) from dominating small-value ones (like number of bathrooms)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ae68305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_processed.drop(columns=[\"Price\"])\n",
    "y = df_processed[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7446d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize/Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9a89ae",
   "metadata": {},
   "source": [
    "Train-Test Split\n",
    "\n",
    "Split dataset into 80% training (11,696 rows) and 20% testing (2,924 rows).\n",
    "\n",
    "Why This Matters\n",
    "\n",
    "Clean and scaled data improves model performance, avoids bias towards certain features, and ensures reliable predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d584447f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d0379b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (11696, 88)\n",
      "Testing data shape: (2924, 88)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
